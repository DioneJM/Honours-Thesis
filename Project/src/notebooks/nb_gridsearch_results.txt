For: Cat1
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
For: Cat2
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
For: Cat3
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
For: Cat4
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
For: Cat5
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
For: Cat6
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
For: Cat7
GridSearchCV(cv=10, error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        s...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={'vec__max_df': (0.5, 0.625, 0.75, 0.875, 1.0), 'vec__max_features': (None, 5000, 10000, 20000), 'vec__min_df': (1, 5, 10, 20, 50), 'tfidf__use_idf': (True, False), 'tfidf__sublinear_tf': (True, False), 'vec__binary': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
=======================
