{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Tests\n",
    "\n",
    "This notebook includes the classifiers that will be used to determine the performance of the deep learning-based classifier.\n",
    "\n",
    "### Classifiers:\n",
    "\n",
    "1) Naive Bayes\n",
    "\n",
    "2) Support Vector Machines (SVM)\n",
    "\n",
    "### Performance Measures:\n",
    "\n",
    "1) Storage requirements of the classifier and feature representation used\n",
    "\n",
    "2) Training time of the classifier\n",
    "\n",
    "3) Speed of the classifier\n",
    "\n",
    "4) Accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DM\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "# Helpful variables\n",
    "EXT_DATA_FOLDER = \"C:\\\\Users\\\\Admin\\\\Projects\\\\thesis\\\\data\\\\\"\n",
    "EXT_DATA_FOLDER2 = \"B:\\\\Datasets\\\\\"\n",
    "\n",
    "ANALYSIS_SAMPLES = os.path.join(EXT_DATA_FOLDER, \"Credibility_Analysis_Samples\\\\September_25\\\\\")\n",
    "dataset_columns = ['Identifier', 'Type', 'Category', 'URL', 'Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5',\n",
    " 'Cat6', 'Cat7', 'Score', 'First date_time', 'Tweets', 'Likes', 'Retweets',\n",
    " 'Potential exposure', 'HTML', 'TEXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "# nltk.download('punkt') #uncomment if running on new machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in csv and excel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(corpus_path, annotated_samples):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    corpus_path: Path for a CSV file containing a list of article URLs and its article text\n",
    "    annotated_samples: Path of the excel file containing articles and its associated URL along with its labels\n",
    "    \n",
    "    Method:\n",
    "    Retrieves the article text by matching the URLs within the corpus_path and annotated_samples and creates a dataframe \n",
    "    containing the URL, article text and the article's corresponding labels.\n",
    "    \n",
    "    Output:\n",
    "    A pandas dataframe\n",
    "    \"\"\"\n",
    "    article_corpus = pd.read_csv(corpus_path)\n",
    "    annotated_corpus = pd.read_excel((annotated_samples))\n",
    "    article_corpus.columns = [\"URL\", \"HTML\", \"TEXT\"]\n",
    "    annotated_articles = annotated_corpus.loc[(annotated_corpus[\"Cat7\"] == 0) | (annotated_corpus[\"Cat7\"] == 1)]\n",
    "    dataset = pd.merge(annotated_articles, article_corpus, how='left', on='URL')\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1116, 3)\n",
      "65    TITLE: Anti-vaccine activists just sparked a U...\n",
      "Name: TEXT, dtype: object\n",
      "Empty DataFrame\n",
      "Columns: [URL, HTML, TEXT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "article_corpus = pd.read_csv(corpus_path)\n",
    "article_corpus.columns = [\"URL\", \"HTML\", \"TEXT\"]\n",
    "print(article_corpus.shape)\n",
    "\n",
    "print(article_corpus.loc[article_corpus[\"URL\"] == \"https://www.thestar.com/news/world/2017/05/07/anti-vaccine-activists-just-sparked-a-us-states-worst-measles-outbreak-in-decades.html\"][\"TEXT\"])\n",
    "print(article_corpus.loc[article_corpus[\"URL\"] == \"https://www.newscientist.com/article/mg23531335-800-cancer-vaccines-could-prime-our-own-bodies-to-fight-tumours/?utm_campaign=RSS%7CNSNS&utm_source=NSNS&utm_medium=RSS&campaign_id=RSS%7CNSNS-\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Identifier' 'Type' 'Category' 'URL' 'Cat1' 'Cat2' 'Cat3' 'Cat4' 'Cat5'\n",
      " 'Cat6' 'Cat7' 'Score' 'First date_time' 'Tweets' 'Likes' 'Retweets'\n",
      " 'Potential exposure' 'HTML' 'TEXT']\n",
      "(447, 19)\n"
     ]
    }
   ],
   "source": [
    "corpus_path = os.path.join(EXT_DATA_FOLDER, \"url_text.csv\")\n",
    "excel_files = [\"sample_third_adam_new.xlsx\", \"sample_third_amalie_new.xlsx\", \"sample_third_maryke_new.xlsx\"]\n",
    "\n",
    "df_files = []\n",
    "\n",
    "for filename in excel_files:\n",
    "    annotated_path = os.path.join(ANALYSIS_SAMPLES, filename)\n",
    "    data = create_dataset(corpus_path, annotated_path)\n",
    "    df_files.append(data)\n",
    "    \n",
    "dataset = pd.concat(df_files)\n",
    "\n",
    "print(dataset.columns.values)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September_13\\sample_third_amalie_new.xlsx\n",
      "September_13\\sample_third_maryke_new.xlsx\n"
     ]
    }
   ],
   "source": [
    "for filename in excel_files[1:]:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://triblive.com/news/healthnow/12759008-74/stronger-flu-vaccine-for-elderly-could-help-younger-adults-with-chronic-conditions\n",
      "TITLE: Stronger flu vaccine for elderly could help younger adults with chronic conditions | TribLIVE\n",
      "TEXT:     “Persons who have these conditions have a much greater risk of the flu being more severe to the point of needing to be hospitalized,” Dr. Ken Smith, professor of medicine at Pitt and co-author of the paper, told the Tribune-Review on Thursday. “If you are hospitalized with the flu, your risk of dying is certainly something that is a possibility.”  The high-dose vaccine is recommended for the elderly population because their immune response to the standard-dose vaccine lessens as they age. However, the price for a standard dose is about $11, while the stronger vaccine is about $31 per dose, Smith said. He said the dose for the elderly is about 24 percent stronger than a standard vaccine.   “The growing proportion of middle-aged adults with chronic health conditions coupled with the modest effectiveness of the standard-dose influenza vaccine prompted us to explore whether existing vaccines already recommended for the elderly also could protect younger people,” lead author Jonathan Raviotta, senior research specialist with The Pittsburgh Vaccination Research Group (PittVax) in Pitt's School of Medicine, said in a statement. “Sure enough, expanding the recommendation does seem like a good policy. ... Before making such a recommendation, real world clinical trials are needed.”          \n",
      "0                                                  NaN\n",
      "1    <!DOCTYPE html>\\n<html\\n  xmlns:og=\"http://ogp...\n",
      "2    <!DOCTYPE html>\\n<html lang=\"en-US\" prefix=\"og...\n",
      "3    <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 T...\n",
      "4    <!DOCTYPE html><html dir=\"ltr\" lang=\"en\" class...\n",
      "Name: HTML, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Example of article with missing text\n",
    "print(dataset.head()[\"URL\"][3])\n",
    "print(dataset.head()[\"TEXT\"][3])  \n",
    "print(dataset.head()[\"HTML\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataset locally\n",
    "writer = pd.ExcelWriter(\"dataset3.xlsx\")\n",
    "dataset.to_excel(writer, \"Sheet1\")\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 19)\n"
     ]
    }
   ],
   "source": [
    "#pre-processing\n",
    "from collections import defaultdict\n",
    "\n",
    "labelled_articles = pd.read_excel(\"dataset3.xlsx\")\n",
    "labelled_articles = labelled_articles.dropna(subset=['TEXT'])\n",
    "print(labelled_articles.shape)\n",
    "criterias = [\"Cat1\", \"Cat2\", \"Cat3\", \"Cat4\", \"Cat5\", \"Cat6\", \"Cat7\"]\n",
    "art_text_sent = np.array([sent_tokenize(article.split(\"TITLE: \")[1].replace(\"TEXT: \",\"\").strip(\" \")) for article in labelled_articles[\"TEXT\"]])\n",
    "art_text_word = np.array([word_tokenize(article.split(\"TITLE: \")[1].replace(\"TEXT: \",\"\").strip(\" \")) for article in labelled_articles[\"TEXT\"]])\n",
    "art_text_sent_word = np.array([[word_tokenize(sent) for sent in article] for article in art_text_sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline classifier performance\n",
    "\n",
    "Performance of classifier is measured using an f1_micro score:\n",
    "\n",
    "'f1_micro': Calculate metrics globally by counting the total true positives, false negatives and false positives and accounts for class imbalance. [Source](https://stackoverflow.com/questions/43421456/computing-macro-f1-score-using-sklearn)\n",
    "\n",
    "f1_micro scores are calculated using stratified k-fold cross validation for k = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "categories = ['Not Satisfied', 'Satisfied']\n",
    "nb_bow = []\n",
    "nb_tfidf = []\n",
    "nb_w2v = []\n",
    "svm_bow = []\n",
    "svm_tfidf = []\n",
    "svm_w2v = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Cat1:\n",
      "NB Average micro f1-score: 0.89 (+/- 0.05)\n",
      "SVM Average micro f1-score: 0.68 (+/- 0.25)\n",
      "For Cat2:\n",
      "NB Average micro f1-score: 0.82 (+/- 0.07)\n",
      "SVM Average micro f1-score: 0.77 (+/- 0.07)\n",
      "For Cat3:\n",
      "NB Average micro f1-score: 0.89 (+/- 0.04)\n",
      "SVM Average micro f1-score: 0.83 (+/- 0.11)\n",
      "For Cat4:\n",
      "NB Average micro f1-score: 0.88 (+/- 0.08)\n",
      "SVM Average micro f1-score: 0.80 (+/- 0.07)\n",
      "For Cat5:\n",
      "NB Average micro f1-score: 0.79 (+/- 0.05)\n",
      "SVM Average micro f1-score: 0.77 (+/- 0.09)\n",
      "For Cat6:\n",
      "NB Average micro f1-score: 0.78 (+/- 0.09)\n",
      "SVM Average micro f1-score: 0.73 (+/- 0.09)\n",
      "For Cat7:\n",
      "NB Average micro f1-score: 0.82 (+/- 0.04)\n",
      "SVM Average micro f1-score: 0.79 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "for criteria in criterias:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(labelled_articles[\"TEXT\"]), list(labelled_articles[criteria]), test_size=int(20))\n",
    "\n",
    "    nb_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         #('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB()),])\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    nb_predicted = list(nb_clf.predict(X_test))\n",
    "    #print(\"Actual vs. NB Predicted labels:\\n\" + str(y_test) + \"\\n\" + str(nb_predicted))\n",
    "\n",
    "    #print(metrics.classification_report(y_test, nb_predicted, target_names=categories))\n",
    "\n",
    "    cv_scores = cross_val_score(nb_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "    print(\"For \" + criteria + \":\")\n",
    "    print(\"NB Average micro f1-score: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std()))\n",
    "    nb_bow.append((cv_scores.mean(), cv_scores.std()))\n",
    "\n",
    "    svm_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         #('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    svm_predicted = list(svm_clf.predict(X_test))\n",
    "    #print(\"Actual vs. SVM Predicted labels:\\n\" + str(y_test) + \"\\n\" + str(svm_predicted))\n",
    "\n",
    "    #print(metrics.classification_report(y_test, svm_predicted, target_names=categories))\n",
    "\n",
    "    svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "    print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    svm_bow.append((svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "#print(nb_f1_scores)\n",
    "#print(\"====\")\n",
    "#print(svm_f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Cat1:\n",
      "NB Average micro f1-score: 0.80 (+/- 0.02)\n",
      "SVM Average micro f1-score: 0.84 (+/- 0.08)\n",
      "For Cat2:\n",
      "NB Average micro f1-score: 0.77 (+/- 0.01)\n",
      "SVM Average micro f1-score: 0.83 (+/- 0.09)\n",
      "For Cat3:\n",
      "NB Average micro f1-score: 0.89 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.89 (+/- 0.02)\n",
      "For Cat4:\n",
      "NB Average micro f1-score: 0.81 (+/- 0.02)\n",
      "SVM Average micro f1-score: 0.87 (+/- 0.05)\n",
      "For Cat5:\n",
      "NB Average micro f1-score: 0.77 (+/- 0.01)\n",
      "SVM Average micro f1-score: 0.76 (+/- 0.06)\n",
      "For Cat6:\n",
      "NB Average micro f1-score: 0.69 (+/- 0.01)\n",
      "SVM Average micro f1-score: 0.76 (+/- 0.07)\n",
      "For Cat7:\n",
      "NB Average micro f1-score: 0.82 (+/- 0.02)\n",
      "SVM Average micro f1-score: 0.81 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "for criteria in criterias:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(labelled_articles[\"TEXT\"]), list(labelled_articles[criteria]), test_size=int(20))\n",
    "\n",
    "    nb_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB()),])\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    nb_predicted = list(nb_clf.predict(X_test))\n",
    "    #print(\"Actual vs. NB Predicted labels:\\n\" + str(y_test) + \"\\n\" + str(nb_predicted))\n",
    "\n",
    "\n",
    "    #print(metrics.classification_report(y_test, nb_predicted, target_names=categories))\n",
    "\n",
    "    cv_scores = cross_val_score(nb_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "    print(\"For \" + criteria + \":\")\n",
    "    print(\"NB Average micro f1-score: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std()))\n",
    "    nb_tfidf.append((cv_scores.mean(), cv_scores.std()))\n",
    "\n",
    "    svm_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    svm_predicted = list(svm_clf.predict(X_test))\n",
    "    #print(\"Actual vs. SVM Predicted labels:\\n\" + str(y_test) + \"\\n\" + str(svm_predicted))\n",
    "\n",
    "    #print(metrics.classification_report(y_test, svm_predicted, target_names=categories))\n",
    "\n",
    "    svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "    print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    svm_tfidf.append((svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "#print(nb_f1_scores)\n",
    "#print(\"====\")\n",
    "#print(svm_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.items())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.items())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(EXT_DATA_FOLDER2, \"glove.6B.300d.txt\"), \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'the'    <map object at 0x00000127D8974390>\n",
       "b','      <map object at 0x00000127D8974C18>\n",
       "b'.'      <map object at 0x00000127D8974B00>\n",
       "b'of'     <map object at 0x00000127D8974A20>\n",
       "b'to'     <map object at 0x00000127D8974EB8>\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame.from_dict(w2v, orient='index')\n",
    "w2v_df.head()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec with Mean Embedding Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Cat1:\n",
      "NB Average micro f1-score: 0.79 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.60 (+/- 0.28)\n",
      "For Cat2:\n",
      "NB Average micro f1-score: 0.79 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.60 (+/- 0.27)\n",
      "For Cat3:\n",
      "NB Average micro f1-score: 0.92 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.92 (+/- 0.00)\n",
      "For Cat4:\n",
      "NB Average micro f1-score: 0.81 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.60 (+/- 0.29)\n",
      "For Cat5:\n",
      "NB Average micro f1-score: 0.76 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.76 (+/- 0.00)\n",
      "For Cat6:\n",
      "NB Average micro f1-score: 0.66 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.56 (+/- 0.15)\n",
      "For Cat7:\n",
      "NB Average micro f1-score: 0.81 (+/- 0.00)\n",
      "SVM Average micro f1-score: 0.60 (+/- 0.29)\n"
     ]
    }
   ],
   "source": [
    "from gensim.sklearn_api import W2VTransformer\n",
    "\n",
    "for criteria in criterias:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(labelled_articles[\"TEXT\"]), list(labelled_articles[criteria]), test_size=int(20))\n",
    "\n",
    "    print(\"For \" + criteria + \":\")\n",
    "    \n",
    "    \n",
    "    nb_clf = Pipeline([('w2v', MeanEmbeddingVectorizer(w2v)),\n",
    "                         ('clf', MultinomialNB()),])\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "\n",
    "    nb_predicted = nb_clf.predict(X_test)\n",
    "    #print(metrics.classification_report(y_test, nb_predicted, target_names=categories))\n",
    "    nb_cv_scores = cross_val_score(nb_clf, X_train, y_train, scoring='f1_micro')\n",
    "    \n",
    "    \n",
    "    print(\"NB Average micro f1-score: %0.2f (+/- %0.2f)\" % (nb_cv_scores.mean(), nb_cv_scores.std()))\n",
    "    nb_w2v.append((nb_cv_scores.mean(), nb_cv_scores.std()))\n",
    "    \n",
    "    \n",
    "    svm_clf = Pipeline([('w2v', MeanEmbeddingVectorizer(w2v)),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "    \n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    svm_predicted = svm_clf.predict(X_test)\n",
    "    svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, scoring='f1_micro')\n",
    "    print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    svm_w2v.append((svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec with Tf-idf Weighted Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Cat1:\n"
     ]
    }
   ],
   "source": [
    "from gensim.sklearn_api import W2VTransformer\n",
    "\n",
    "for criteria in criterias:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(labelled_articles[\"TEXT\"]), list(labelled_articles[criteria]), test_size=int(20))\n",
    "\n",
    "    print(\"For \" + criteria + \":\")\n",
    "    \n",
    "    \n",
    "    nb_clf = Pipeline([('w2v', TfidfEmbeddingVectorizer(w2v)),\n",
    "                         ('clf', MultinomialNB()),])\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "\n",
    "    nb_predicted = nb_clf.predict(X_test)\n",
    "    #print(metrics.classification_report(y_test, nb_predicted, target_names=categories))\n",
    "    nb_cv_scores = cross_val_score(nb_clf, X_train, y_train, scoring='f1_micro')\n",
    "    \n",
    "    \n",
    "    print(\"NB Average micro f1-score: %0.2f (+/- %0.2f)\" % (nb_cv_scores.mean(), nb_cv_scores.std()))\n",
    "    nb_w2v.append((nb_cv_scores.mean(), nb_cv_scores.std()))\n",
    "\n",
    "    \n",
    "    svm_clf = Pipeline([('w2v', TfidfEmbeddingVectorizer(w2v)),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "    \n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    svm_predicted = svm_clf.predict(X_test)\n",
    "    svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, scoring='f1_micro')\n",
    "    print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    svm_w2v.append((svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(twenty_train.target))\n",
    "print(len(cat7_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Training set size ====\n",
      "# of articles in testing set: 52\n",
      "Number of articles that satisfy this category (=1): 13\n",
      "\n",
      "===== Testing set size ====\n",
      "# of articles in testing set: 14\n",
      "Number of articles that satisfy this category (=1): 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dividing into training and testing set\n",
    "\n",
    "#merge text and scores\n",
    "cat4_dataset = np.array(list(zip(art_text, cat4_scores)))\n",
    "\n",
    "#TODO: split this dataset into training and testing and then pass these into the next cell\n",
    "#training_set = cat4_dataset[:int(len(cat4_dataset)*0.8)]\n",
    "#testing_set = cat4_dataset[int(len(cat4_dataset)*0.8):]\n",
    "\n",
    "split = 0.8\n",
    "training_articles = art_text[:int(len(art_text)*split)]\n",
    "training_preds = cat4_scores[:int(len(cat4_scores)*split)]\n",
    "\n",
    "testing_articles = art_text[int(len(art_text)*split):]\n",
    "testing_preds = cat4_scores[int(len(cat4_scores)*split):]\n",
    "print(\"===== Training set size ====\")\n",
    "print(\"# of articles in testing set: {}\".format(len(training_preds)))\n",
    "print(\"Number of articles that satisfy this category (=1): {}\\n\".format(len(training_preds[training_preds == 1])))\n",
    "\n",
    "print(\"===== Testing set size ====\")\n",
    "print(\"# of articles in testing set: {}\".format(len(testing_preds)))\n",
    "print(\"Number of articles that satisfy this category (=1): {}\\n\".format(len(testing_preds[testing_preds == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 52\n",
      "Naive Bayes correct prediction: 0.93\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Satisfies       0.93      1.00      0.96        13\n",
      "    Satisfies       0.00      0.00      0.00         1\n",
      "\n",
      "  avg / total       0.86      0.93      0.89        14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM correct prediction: 0.93\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Satisfies       0.93      1.00      0.96        13\n",
      "    Satisfies       0.00      0.00      0.00         1\n",
      "\n",
      "  avg / total       0.86      0.93      0.89        14\n",
      "\n",
      "[[13  0]\n",
      " [ 1  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "categories = ['Not Satisfies', 'Satisfies']\n",
    "\n",
    "print(\"Number of articles: {}\".format(len(training_articles)))\n",
    "\n",
    "docs_test = testing_articles\n",
    "\n",
    "# Naive Bayes classifier\n",
    "bayes_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB())\n",
    "                      ])\n",
    "bayes_clf.fit(training_articles, training_preds)\n",
    "joblib.dump(bayes_clf, \"naive_bayes.pkl\", compress=9)\n",
    "\n",
    "# Predict the test dataset using Naive Bayes\n",
    "predicted = bayes_clf.predict(docs_test)\n",
    "print('Naive Bayes correct prediction: {:4.2f}'.format(np.mean(predicted == testing_preds)))\n",
    "print(metrics.classification_report(testing_preds, predicted, target_names=categories))\n",
    "\n",
    "# Support Vector Machine (SVM) classifier\n",
    "svm_clf = Pipeline([('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=   5, random_state=42)),\n",
    "])\n",
    "svm_clf.fit(training_articles, training_preds)\n",
    "joblib.dump(svm_clf, \"svm.pkl\", compress=9)\n",
    "# Predict the test dataset using SVM\n",
    "predicted = svm_clf.predict(docs_test)\n",
    "print('SVM correct prediction: {:4.2f}'.format(np.mean(predicted == testing_preds)))\n",
    "print(metrics.classification_report(testing_preds, predicted, target_names=categories))\n",
    "\n",
    "print(metrics.confusion_matrix(testing_preds, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of twent_test.data:  <class 'numpy.ndarray'>\n",
      "66\n",
      "[2 2 2 ... 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"type of twent_test.data: \", type(twenty_train.target))\n",
    "print(len(art_text))\n",
    "print(twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from the generalized text format used by word2vec, GloVe,\n",
    "    fastText, and ConceptNet Numberbatch. The main point where they differ is\n",
    "    whether there is an initial line with the dimensions of the matrix.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pre-trained word2vec\n",
    "pre_word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(datapath(os.path.join(EXT_DATA_FOLDER, \"GoogleNews-vectors-negative300.bin\")), binary=True)\n",
    "pre_word2vec_model.save(\"pre_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of 'woman' and 'man':  0.76640123\n",
      "Similarity of 'woman' and 'woman':  1.0\n",
      "Similarity of 'dog' and 'hotdog':  0.38931656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity of 'woman' and 'man': \", pre_word2vec_model.similarity('woman', 'man'))\n",
    "print(\"Similarity of 'woman' and 'woman': \", pre_word2vec_model.similarity('woman', 'woman'))\n",
    "print(\"Similarity of 'dog' and 'hotdog': \", pre_word2vec_model.similarity('dog', 'hotdog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = load_embeddings(os.path.join(EXT_DATA_FOLDER, \"glove.6B.300d.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x94 in position 19: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-390-9fe00ebe9f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEXT_DATA_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GoogleNews-vectors-negative300.bin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-389-537f58499756>\u001b[0m in \u001b[0;36mload_embeddings\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x94 in position 19: invalid start byte"
     ]
    }
   ],
   "source": [
    "w2v = load_embeddings(os.path.join(EXT_DATA_FOLDER, \"GoogleNews-vectors-negative300.bin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helo\n"
     ]
    }
   ],
   "source": [
    "print (\"Helo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
