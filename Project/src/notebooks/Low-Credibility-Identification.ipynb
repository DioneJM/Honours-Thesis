{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt') #uncomment if running on new machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Helpful variables\n",
    "EXT_DATA_FOLDER = \"C:\\\\Users\\\\Admin\\\\Projects\\\\thesis\\\\data\\\\\"\n",
    "EXT_DATA_FOLDER2 = \"B:\\\\Datasets\\\\\"\n",
    "\n",
    "ANALYSIS_SAMPLES = os.path.join(EXT_DATA_FOLDER, \"Credibility_Analysis_Samples\\\\September_25\\\\\")\n",
    "dataset_columns = ['Identifier', 'Type', 'Category', 'URL', 'Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5',\n",
    " 'Cat6', 'Cat7', 'Score', 'First date_time', 'Tweets', 'Likes', 'Retweets',\n",
    " 'Potential exposure', 'HTML', 'TEXT']\n",
    "criterias = [\"Cat1\", \"Cat2\", \"Cat3\", \"Cat4\", \"Cat5\", \"Cat6\", \"Cat7\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Credibility Score Detector\n",
    "\n",
    "1) Create a dataset that separates he articles as having low credibility and not low credibility where low credibility is defined to be articles with a credibility score of less than 3\n",
    "\n",
    "2.a) Apply the ensemble of models to classify an article for each category and then use the resulting score to determine whether an article's credibility is low or not\n",
    "\n",
    "2.b) Apply a new model that has been trained to solely just determine whether an article's credibility is low or not\n",
    "\n",
    "3) ???\n",
    "\n",
    "4) Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "labelled_articles = pd.read_excel(\"dataset5.xlsx\")\n",
    "labelled_articles = labelled_articles.dropna(subset=['TEXT'])\n",
    "labelled_articles = labelled_articles[pd.to_numeric(labelled_articles['Cat1'], errors='coerce').notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_articles['Low Credibility'] = np.where(labelled_articles['Score'] < 3, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and saving model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_text_sent = np.array([sent_tokenize(article.split(\"TITLE: \")[1].replace(\"TEXT: \",\"\").strip(\" \")) for article in labelled_articles[\"TEXT\"]])\n",
    "art_text_word = np.array([word_tokenize(article.split(\"TITLE: \")[1].replace(\"TEXT: \",\"\").strip(\" \")) for article in labelled_articles[\"TEXT\"]])\n",
    "art_text_sent_word = np.array([[word_tokenize(sent) for sent in article] for article in art_text_sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thousands of parents describe their children as ‘fine’ one day, then their children suddenly develop autism (a neurological regression) after vaccines.'\n",
      " 'What does the science say?' 'It agrees…']\n",
      "[[list(['Thousands', 'of', 'parents', 'describe', 'their', 'children', 'as', '‘', 'fine', '’', 'one', 'day', ',', 'then', 'their', 'children', 'suddenly', 'develop', 'autism', '(', 'a', 'neurological', 'regression', ')', 'after', 'vaccines', '.'])\n",
      "  list(['What', 'does', 'the', 'science', 'say', '?'])\n",
      "  list(['It', 'agrees…'])]]\n"
     ]
    }
   ],
   "source": [
    "excerpt = \"\"\"Thousands of parents describe their children as ‘fine’ one day, then their children suddenly develop autism (a neurological regression) after vaccines.\n",
    "             What does the science say? It agrees…\"\"\"\n",
    "\n",
    "sentences = np.array(sent_tokenize(excerpt))\n",
    "print(sentences)\n",
    "final = np.array([[word_tokenize(sent) for sent in sentences]])\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for criteria in criterias:\n",
    "    print(\"Training Classifier for \" + criteria + \":\")\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(labelled_articles[\"TEXT\"]), list(labelled_articles[criteria]), test_size=int(20))\n",
    "\n",
    "    svm_clf = Pipeline([('vect', CountVectorizer(max_features=10)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    svm_predicted = list(svm_clf.predict(X_test))\n",
    "    svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "\n",
    "    print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    joblib.dump(svm_clf, 'models/svm_clf_tfidf_stop_' + criteria + '.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Model Approach\n",
    "SVM + TF-IDF with stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train(article_text, labels, criteria):\n",
    "    print(\"Training Classifier for \" + criteria + \":\")\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(article_text, labels, test_size=int(20))\n",
    "\n",
    "    svm_clf = Pipeline([('vect', CountVectorizer(max_features=10)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    svm_predicted = list(svm_clf.predict(X_test))\n",
    "    svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "\n",
    "    print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "    joblib.dump(svm_clf, 'models/svm_clf_tfidf_stop_' + criteria + '.joblib')\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
