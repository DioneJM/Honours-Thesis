{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt') #uncomment if running on new machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gensim\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Helpful variables\n",
    "EXT_DATA_FOLDER = \"C:\\\\Users\\\\Admin\\\\Projects\\\\thesis\\\\data\\\\\"\n",
    "EXT_DATA_FOLDER2 = \"B:\\\\Datasets\\\\\"\n",
    "\n",
    "ANALYSIS_SAMPLES = os.path.join(EXT_DATA_FOLDER, \"Credibility_Analysis_Samples\\\\September_25\\\\\")\n",
    "dataset_columns = ['Identifier', 'Type', 'Category', 'URL', 'Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5',\n",
    " 'Cat6', 'Cat7', 'Score', 'First date_time', 'Tweets', 'Likes', 'Retweets',\n",
    " 'Potential exposure', 'HTML', 'TEXT']\n",
    "criterias = [\"Cat1\", \"Cat2\", \"Cat3\", \"Cat4\", \"Cat5\", \"Cat6\", \"Cat7\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Credibility Score Detector\n",
    "\n",
    "1) Create a dataset that separates he articles as having low credibility and not low credibility where low credibility is defined to be articles with a credibility score of less than 3\n",
    "\n",
    "2.a) Apply the ensemble of models to classify an article for each category and then use the resulting score to determine whether an article's credibility is low or not\n",
    "\n",
    "2.b) Apply a new model that has been trained to solely just determine whether an article's credibility is low or not\n",
    "\n",
    "3) ???\n",
    "\n",
    "4) Profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the manually labelled articles from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470, 21)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "labelled_articles = pd.read_excel(\"dataset5.xlsx\")\n",
    "labelled_articles = labelled_articles.dropna(subset=['TEXT'])\n",
    "labelled_articles = labelled_articles[pd.to_numeric(labelled_articles['Cat1'], errors='coerce').notnull()]\n",
    "for criteria in criterias:\n",
    "    labelled_articles = labelled_articles.dropna(subset=[criteria])\n",
    "print(labelled_articles.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Training and testing sets for 2 classification tasks\n",
    "\n",
    "1) Make a training and testing set for classfying whether an article has low credibility or not\n",
    "\n",
    "2) Make a training and testing set for classifying whether an article satisfies each criteria and then using these outputs do determine whether the article has low crediibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit1_labels = labelled_articles[\"Cat1\"]\n",
    "crit2_labels = labelled_articles[\"Cat2\"]\n",
    "crit3_labels = labelled_articles[\"Cat3\"]\n",
    "crit4_labels = labelled_articles[\"Cat4\"]\n",
    "crit5_labels = labelled_articles[\"Cat5\"]\n",
    "crit6_labels = labelled_articles[\"Cat6\"]\n",
    "crit7_labels = labelled_articles[\"Cat7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = [article.split(\"TITLE: \")[1].replace(\"TEXT: \",\"\").strip(\" \") for article in labelled_articles[\"TEXT\"]]\n",
    "\n",
    "#If score < cred_thresh than article isn't credible\n",
    "cred_thresh = 3\n",
    "labelled_articles['Credible'] = np.where(labelled_articles['Score'] < cred_thresh, 0, 1)\n",
    "low_cred_labels = list(labelled_articles[\"Credible\"])\n",
    "num_runs = 10\n",
    "seeds = [random.randint(1,100000) for i in range(num_runs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "print(len(labelled_articles[labelled_articles['Credible'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Model Approach\n",
    "SVM + TF-IDF with stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_build_train(article_text, labels, seed=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(list(article_text), [int(label) for label in labels], random_state=seed, test_size=0.10)\n",
    "    svm_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    model = {\"model\": svm_clf,\n",
    "             \"X_train\": X_train, \n",
    "             \"X_test\": X_test,\n",
    "             \"y_train\": y_train,\n",
    "             \"y_test\": y_test}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Scores vs Actual Scores:\n",
      "[5, 1, 3, 4, 4, 5, 4, 3, 1, 5, 3, 3, 4, 4, 5, 5, 4, 4, 4, 4, 3, 4, 5, 5, 4, 4, 0, 5, 4, 4, 3, 4, 4, 4, 3, 1, 5, 4, 4, 3, 1, 4, 3, 4, 4, 2, 4]\n",
      "[3, 2, 4, 5, 4, 6, 5, 1, 2, 4, 4, 4, 3, 3, 3, 6, 6, 6, 5, 4, 3, 4, 4, 4, 4, 0, 2, 7, 3, 4, 5, 4, 4, 4, 1, 0, 5, 5, 3, 1, 4, 3, 2, 4, 4, 2, 3]\n",
      "% Correct: 0.8723404255319149\n",
      "Average difference when correct: 0.8536585365853658\n",
      "Average difference when incorrect: 2.3333333333333335\n",
      "Micro averaged f1-scores: 0.8936170212765957\n",
      "Micro averaged precision scores: 0.8936170212765957\n",
      "Micro averaged recall scores: 0.8936170212765957\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "models = defaultdict(str)\n",
    "seed = random.randint(1,10000)\n",
    "#Train a classifier for all 7 criteria\n",
    "for criteria in criterias:\n",
    "    models[criteria] = svm_build_train(article_text, labelled_articles[criteria], seed)\n",
    "\n",
    "#Replicate the X and y test sets to get the actual credibility score\n",
    "X2_train, X2_test, y2_train, credibility_scores = train_test_split(article_text, list(labelled_articles[\"Score\"]), random_state=seed, test_size=0.10)\n",
    "X2_train, X2_test, y2_train, low_credibility_labels = train_test_split(article_text, list(labelled_articles[\"Credible\"]), random_state=seed, test_size=0.10)\n",
    "\n",
    "#for each criteria, I get the use the model that I trained specifically for it and get it to predict on the articles stored in the X_test set\n",
    "#The results are then stored in 'label_predictions' where it is a 7xN matrix where N is the number of articles in the test sets\n",
    "label_predictions = []\n",
    "for criteria in criterias:\n",
    "    predictions = list(models[criteria]['model'].predict(models[criteria]['X_test']))\n",
    "    label_predictions.append(predictions)\n",
    "\n",
    "#The predictions are then tallied up and compared with the actual credibility score of the article\n",
    "#And the score difference when it correctly and incorrectly identifies\n",
    "predicted_scores = [0 for i in range(len(credibility_scores))]\n",
    "for label in label_predictions:\n",
    "    for article in range(len(label)):\n",
    "        predicted_scores[article] = predicted_scores[article] + label[article]\n",
    "\n",
    "print(\"Predicted Scores vs Actual Scores:\\n{}\\n{}\".format(predicted_scores, credibility_scores))\n",
    "\n",
    "identified = []\n",
    "correct_diff = []\n",
    "incorrect_diff = []\n",
    "for i in range(len(credibility_scores)):\n",
    "    if((credibility_scores[i] < cred_thresh and predicted_scores[i] < cred_thresh) or (credibility_scores[i] >= cred_thresh and predicted_scores[i] >= cred_thresh)) :\n",
    "        identified.append(1)\n",
    "        correct_diff.append(abs(credibility_scores[i] - predicted_scores[i]))\n",
    "    else:\n",
    "        incorrect_diff.append(abs(credibility_scores[i] - predicted_scores[i]))\n",
    "\n",
    "identified_avg = len(identified)/len(credibility_scores)\n",
    "print(\"% Correct: {}\".format(identified_avg))\n",
    "correct_diff_avg = np.array(correct_diff).mean()\n",
    "incorrect_diff_avg = np.array(incorrect_diff).mean()\n",
    "print(\"Average difference when correct: {}\\nAverage difference when incorrect: {}\".format(correct_diff_avg, incorrect_diff_avg))\n",
    "\n",
    "#Calculating the micro averaged f1 score\n",
    "\n",
    "#Converting the predicted scores into a credibility label\n",
    "low_credibility_preds = []\n",
    "for i in range(len(credibility_scores)):\n",
    "        if((credibility_scores[i] < cred_thresh and predicted_scores[i] < cred_thresh)):\n",
    "            low_credibility_preds.append(0)\n",
    "        else:\n",
    "            low_credibility_preds.append(1)\n",
    "        \n",
    "print(\"Micro averaged f1-scores: {}\".format(f1_score(low_credibility_labels, low_credibility_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged precision scores: {}\".format(precision_score(low_credibility_labels, low_credibility_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged recall scores: {}\".format(recall_score(low_credibility_labels, low_credibility_preds, labels=[0,1], average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsvm_predicted = list(svm_clf.predict(X_test))\\nsvm_cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=10, scoring=\\'f1_micro\\')\\n\\nprint(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\\njoblib.dump(svm_clf, \\'models/svm_clf_tfidf_stop_\\' + criteria + \\'.joblib\\')\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "svm_predicted = list(svm_clf.predict(X_test))\n",
    "svm_cv_scores = cross_val_score(svm_clf, X_train, y_train, cv=10, scoring='f1_micro')\n",
    "\n",
    "print(\"SVM Average micro f1-score: %0.2f (+/- %0.2f)\" % (svm_cv_scores.mean(), svm_cv_scores.std()))\n",
    "joblib.dump(svm_clf, 'models/svm_clf_tfidf_stop_' + criteria + '.joblib')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple runs of test to get idea of average accuracy and average difference between scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "IMAGE_FOLDER = \"C:\\\\Users\\\\Admin\\\\OneDrive - Macquarie University\\\\Uni\\\\2018 Semester 2\\\\ENGG411\\\\Honours-Thesis\\\\Thesis\\\\images\"\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, filename,\n",
    "                          normalize=False,\n",
    "                          title='',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(os.path.join(IMAGE_FOLDER, filename), bbox_inches='tight')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_roc(y_true, y_score, filename):\n",
    "    probs = total_y_scores\n",
    "    preds = total_low_cred_labels\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_true, y_score)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('ROC of Binary Classifier')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig(os.path.join(IMAGE_FOLDER, filename), bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 10 runs:\n",
      "\n",
      "Average correctly identified %: 0.9148936170212766\n",
      "\n",
      "Average score difference when correctly classified: 0.6976744186046512\n",
      "\n",
      "Average score difference when incorrectly classified: 1.75\n",
      "\n",
      "Accuracy: 0.9574468085106383\n",
      "Micro averaged f1-scores: 0.9574468085106385\n",
      "Macro averaged f1-scores: 0.9044715447154471\n",
      "Binary averaged f1-scores: 0.975609756097561\n",
      "Micro averaged precision scores: 0.9574468085106383\n",
      "Micro averaged recall scores: 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_identified = []\n",
    "total_correct_diff = []\n",
    "total_incorrect_diff = []\n",
    "total_single_low_cred_preds = []\n",
    "total_low_cred_labels = []\n",
    "\n",
    "total_y_scores = []\n",
    "total_y_test = []\n",
    "\n",
    "for seed in seeds[:1]:\n",
    "    models = defaultdict(str)\n",
    "    #Train a classifier for all 7 criteria\n",
    "    for criteria in criterias:\n",
    "        models[criteria] = svm_build_train(article_text, labelled_articles[criteria], seed)\n",
    "\n",
    "    #Replicate the X and y test sets to get the actual credibility score\n",
    "    X2_train, X2_test, y2_train, credibility_scores = train_test_split(article_text, list(labelled_articles[\"Score\"]), random_state=seed, test_size=0.10)\n",
    "    X2_train, X2_test, y2_train, low_credibility_labels = train_test_split(article_text, list(labelled_articles[\"Credible\"]), random_state=seed, test_size=0.10)\n",
    "\n",
    "    #for each criteria, I get the use the model that I trained specifically for it and get it to predict on the articles stored in the X_test set\n",
    "    #The results are then stored in 'label_predictions' where it is a 7xN matrix where N is the number of articles in the test sets\n",
    "    label_predictions = []\n",
    "    for criteria in criterias:\n",
    "        predictions = list(models[criteria]['model'].predict(models[criteria]['X_test']))\n",
    "        label_predictions.append(predictions)\n",
    "\n",
    "    #The predictions are then tallied up and compared with the actual credibility score of the article\n",
    "    #And the score difference when it correctly and incorrectly identifies\n",
    "    predicted_scores = [0 for i in range(len(credibility_scores))]\n",
    "    for label in label_predictions:\n",
    "        for article in range(len(label)):\n",
    "            predicted_scores[article] = predicted_scores[article] + label[article]\n",
    "    identified = []\n",
    "    correct_diff = []\n",
    "    incorrect_diff = []\n",
    "    for i in range(len(credibility_scores)):\n",
    "        if((credibility_scores[i] < cred_thresh and predicted_scores[i] < cred_thresh) or (credibility_scores[i] >= cred_thresh and predicted_scores[i] >= cred_thresh)):\n",
    "            identified.append(1)\n",
    "            correct_diff.append(abs(credibility_scores[i] - predicted_scores[i]))\n",
    "        else:\n",
    "            incorrect_diff.append(abs(credibility_scores[i] - predicted_scores[i]))\n",
    "            \n",
    "    if(np.array(correct_diff).size == 0):\n",
    "        correct_diff = [0]\n",
    "    \n",
    "    if(np.array(incorrect_diff).size == 0):\n",
    "        incorrect_diff = [0]\n",
    "\n",
    "    identified_avg = len(identified)/len(credibility_scores)\n",
    "    correct_diff_avg = np.array(correct_diff).mean()\n",
    "    incorrect_diff_avg = np.array(incorrect_diff).mean()\n",
    "    \n",
    "    total_identified.append(identified_avg)\n",
    "    total_correct_diff.append(correct_diff_avg)\n",
    "    total_incorrect_diff.append(incorrect_diff_avg)\n",
    "    \n",
    "    #Calculating the micro averaged f1 score\n",
    "\n",
    "    #Converting the predicted scores into a credibility label\n",
    "    low_credibility_preds = []\n",
    "    for i in range(len(credibility_scores)):\n",
    "            if((credibility_scores[i] < cred_thresh and predicted_scores[i] < cred_thresh)):\n",
    "                low_credibility_preds.append(0)\n",
    "            else:\n",
    "                low_credibility_preds.append(1)\n",
    "    total_single_low_cred_preds.extend(low_credibility_preds)\n",
    "    total_low_cred_labels.extend(low_credibility_labels)\n",
    "    total_y_scores.extend((bin_clf['model'].decision_function(bin_clf['X_test'])))\n",
    "\n",
    "    \n",
    "    \n",
    "if(np.array(total_incorrect_diff).size == 0):\n",
    "    total_incorrect_diff = [0]\n",
    "    \n",
    "    \n",
    "print(\"\"\"\n",
    "For {} runs:\\n\n",
    "Average correctly identified %: {}\\n\n",
    "Average score difference when correctly classified: {}\\n\n",
    "Average score difference when incorrectly classified: {}\n",
    "\"\"\".format(num_runs, np.array(total_identified).mean(), np.array(total_correct_diff).mean(), np.array(total_incorrect_diff).mean()))\n",
    "\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(total_low_cred_labels, total_single_low_cred_preds)))\n",
    "print(\"Micro averaged f1-scores: {}\".format(f1_score(total_low_cred_labels, total_single_low_cred_preds, labels=[0,1], average='micro')))\n",
    "print(\"Macro averaged f1-scores: {}\".format(f1_score(total_low_cred_labels, total_single_low_cred_preds, labels=[0,1], average='macro')))\n",
    "print(\"Binary averaged f1-scores: {}\".format(f1_score(total_low_cred_labels, total_single_low_cred_preds, labels=[0,1], average='binary')))\n",
    "print(\"Micro averaged precision scores: {}\".format(precision_score(total_low_cred_labels, total_single_low_cred_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged recall scores: {}\".format(recall_score(total_low_cred_labels, total_single_low_cred_preds, labels=[0,1], average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 67  42]\n",
      " [  0 361]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(total_low_cred_labels, total_single_low_cred_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(total_low_cred_labels, total_single_low_cred_preds).ravel()\n",
    "plot_confusion_matrix(confusion, classes=[\"Low Credibility\", \"High Credibility\"], filename='single-model-performance.png', title=\"Single Model Approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-63dc7c08c52f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_low_cred_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_y_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \"\"\"\n\u001b[0;32m    314\u001b[0m     \u001b[1;31m# Check to make sure y_true is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         raise ValueError('Expected array-like (array or non-string sequence), '\n\u001b[1;32m--> 244\u001b[1;33m                          'got %r' % y)\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[0msparseseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SparseSeries'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got 0"
     ]
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "from sklearn import metrics\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(7):\n",
    "    fpr[i], tpr[i], _ = metrics.roc_curve(total_low_cred_labels[:, i], total_y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-5c21c2de8c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# First aggregate all false positive rates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mall_fpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Then interpolate all ROC curves at this points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Approach\n",
    "Criteria 1: SVM + TF-IDF (stopwords removed)\n",
    "\n",
    "Criteria 2: SVM + TF-IDF (stopwords removed)\n",
    "\n",
    "Criteria 3: SVM + BoW (stopwords removed)\n",
    "\n",
    "Criteria 4: SVM + BoW (stopwords removed)\n",
    "\n",
    "Criteria 5: SVM + TF-IDF (stopwords removed)\n",
    "\n",
    "Criteria 6: SVM + TF-IDF (stopwords removed)\n",
    "\n",
    "Criteria 7: SVM + BoW (all words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_build_train(labelled_articles, seed=42):\n",
    "    \n",
    "    c1_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    c2_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    c3_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    c4_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    c5_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    c6_clf = Pipeline([('vect', CountVectorizer(stop_words='english', analyzer='word', max_features=20000)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    c7_clf = Pipeline([('vect', CountVectorizer(max_features=20000)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                               alpha=1e-3, random_state=69,\n",
    "                                               max_iter=5, tol=None)),])\n",
    "    \n",
    "    article_text = list(labelled_articles[\"TEXT\"])\n",
    "    crit1_labels = [int(label) for label in list(labelled_articles[\"Cat1\"])]\n",
    "    crit2_labels = [int(label) for label in list(labelled_articles[\"Cat2\"])]\n",
    "    crit3_labels = [int(label) for label in list(labelled_articles[\"Cat3\"])]\n",
    "    crit4_labels = [int(label) for label in list(labelled_articles[\"Cat4\"])]\n",
    "    crit5_labels = [int(label) for label in list(labelled_articles[\"Cat5\"])]\n",
    "    crit6_labels = [int(label) for label in list(labelled_articles[\"Cat6\"])]\n",
    "    crit7_labels = [int(label) for label in list(labelled_articles[\"Cat7\"])]\n",
    "    \n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(article_text, crit1_labels, random_state=seed, test_size=0.10)\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(article_text, crit2_labels, random_state=seed, test_size=0.10)\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(article_text, crit3_labels, random_state=seed, test_size=0.10)\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(article_text, crit4_labels, random_state=seed, test_size=0.10)\n",
    "    X5_train, X5_test, y5_train, y5_test = train_test_split(article_text, crit5_labels, random_state=seed, test_size=0.10)\n",
    "    X6_train, X6_test, y6_train, y6_test = train_test_split(article_text, crit6_labels, random_state=seed, test_size=0.10)\n",
    "    X7_train, X7_test, y7_train, y7_test = train_test_split(article_text, crit7_labels, random_state=seed, test_size=0.10)\n",
    "    \n",
    "    c1_clf.fit(X1_train,y1_train)\n",
    "    c2_clf.fit(X2_train,y2_train)\n",
    "    c3_clf.fit(X3_train,y3_train)\n",
    "    c4_clf.fit(X4_train,y4_train)\n",
    "    c5_clf.fit(X5_train,y5_train)\n",
    "    c6_clf.fit(X6_train,y6_train)\n",
    "    c7_clf.fit(X7_train,y7_train)\n",
    "    \n",
    "    ensemble = {\"Cat1\": {\"model\": c1_clf, \"X_train\": X1_train, \"X_test\": X1_test, \"y_train\": y1_train, \"y_test\": y1_test},\n",
    "                \"Cat2\": {\"model\": c2_clf, \"X_train\": X2_train, \"X_test\": X2_test, \"y_train\": y2_train, \"y_test\": y2_test},\n",
    "                \"Cat3\": {\"model\": c3_clf, \"X_train\": X3_train, \"X_test\": X3_test, \"y_train\": y3_train, \"y_test\": y3_test},\n",
    "                \"Cat4\": {\"model\": c4_clf, \"X_train\": X4_train, \"X_test\": X4_test, \"y_train\": y4_train, \"y_test\": y4_test},\n",
    "                \"Cat5\": {\"model\": c5_clf, \"X_train\": X5_train, \"X_test\": X5_test, \"y_train\": y5_train, \"y_test\": y5_test},\n",
    "                \"Cat6\": {\"model\": c6_clf, \"X_train\": X6_train, \"X_test\": X6_test, \"y_train\": y6_train, \"y_test\": y6_test},\n",
    "                \"Cat7\": {\"model\": c7_clf, \"X_train\": X7_train, \"X_test\": X7_test, \"y_train\": y7_train, \"y_test\": y7_test}\n",
    "               }\n",
    "\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 10 runs:\n",
      "\n",
      "Average correctly identified %: 0.8446808510638297\n",
      "\n",
      "Average score difference when correctly classified: 0.706855478115964\n",
      "\n",
      "Average score difference when incorrectly classified: 1.9792857142857145\n",
      "\n",
      "Accuracy: 0.9106382978723404\n",
      "Micro averaged f1-scores: 0.9148936170212766\n",
      "Micro averaged precision scores: 0.9148936170212766\n",
      "Micro averaged recall scores: 0.9148936170212766\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_identified = []\n",
    "total_correct_diff = []\n",
    "total_incorrect_diff = []\n",
    "total_ensemble_low_cred_preds = []\n",
    "total_low_cred_labels = []\n",
    "\n",
    "num_runs = 10\n",
    "for seed in seeds:\n",
    "    #Train a ensemble classifier for all 7 criteria\n",
    "    ensemble = ensemble_build_train(labelled_articles, seed)\n",
    "\n",
    "    #Replicate the X and y test sets to get the actual credibility score\n",
    "    __train, __test, __train, credibility_scores = train_test_split(article_text, list(labelled_articles[\"Score\"]), random_state=seed, test_size=0.10)\n",
    "    __train, __test, __train, low_credibility_labels = train_test_split(article_text, list(labelled_articles[\"Credible\"]), random_state=seed, test_size=0.10)\n",
    "\n",
    "    #for each criteria, I get the use the model that I trained specifically for it and get it to predict on the articles stored in the X_test set\n",
    "    #The results are then stored in 'label_predictions' where it is a 7xN matrix where N is the number of articles in the test sets\n",
    "    label_predictions = []\n",
    "    for criteria in criterias:\n",
    "        predictions = list(ensemble[criteria]['model'].predict(ensemble[criteria]['X_test']))\n",
    "        label_predictions.append(predictions)\n",
    "\n",
    "    #The predictions are then tallied up and compared with the actual credibility score of the article\n",
    "    #And the score difference when it correctly and incorrectly identifies\n",
    "    predicted_scores = [0 for i in range(len(credibility_scores))]\n",
    "    for label in label_predictions:\n",
    "        for article in range(len(label)):\n",
    "            predicted_scores[article] = predicted_scores[article] + label[article]\n",
    "    identified = []\n",
    "    correct_diff = []\n",
    "    incorrect_diff = []\n",
    "    for i in range(len(credibility_scores)):\n",
    "        if((credibility_scores[i] < cred_thresh and predicted_scores[i] < cred_thresh) or (credibility_scores[i] >= cred_thresh and predicted_scores[i] >= cred_thresh)) :\n",
    "            identified.append(1)\n",
    "            correct_diff.append(abs(credibility_scores[i] - predicted_scores[i]))\n",
    "        else:\n",
    "            incorrect_diff.append(abs(credibility_scores[i] - predicted_scores[i]))\n",
    "\n",
    "    identified_avg = len(identified)/len(credibility_scores)\n",
    "    correct_diff_avg = np.array(correct_diff).mean()\n",
    "    incorrect_diff_avg = np.array(incorrect_diff).mean()\n",
    "    \n",
    "    total_identified.append(identified_avg)\n",
    "    total_correct_diff.append(correct_diff_avg)\n",
    "    total_incorrect_diff.append(incorrect_diff_avg)\n",
    "    \n",
    "    #Calculating the micro averaged f1 score\n",
    "\n",
    "    #Converting the predicted scores into a credibility label\n",
    "    low_credibility_preds = []\n",
    "    for i in range(len(credibility_scores)):\n",
    "            if((credibility_scores[i] < cred_thresh and predicted_scores[i] < cred_thresh)):\n",
    "                low_credibility_preds.append(0)\n",
    "            else:\n",
    "                low_credibility_preds.append(1)\n",
    "    total_ensemble_low_cred_preds.extend(low_credibility_preds)\n",
    "    total_low_cred_labels.extend(low_credibility_labels)\n",
    "    \n",
    "    \n",
    "if(np.isnan(np.array(total_incorrect_diff).mean())):\n",
    "    total_incorrect_df = [0]\n",
    "    \n",
    "    \n",
    "print(\"\"\"\n",
    "For {} runs:\\n\n",
    "Average correctly identified %: {}\\n\n",
    "Average score difference when correctly classified: {}\\n\n",
    "Average score difference when incorrectly classified: {}\n",
    "\"\"\".format(num_runs, np.array(total_identified).mean(), np.array(total_correct_diff).mean(), np.array(total_incorrect_diff).mean()))\n",
    "\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(total_low_cred_labels, total_single_low_cred_preds)))\n",
    "print(\"Micro averaged f1-scores: {}\".format(f1_score(total_low_cred_labels, total_ensemble_low_cred_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged precision scores: {}\".format(precision_score(total_low_cred_labels, total_ensemble_low_cred_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged recall scores: {}\".format(recall_score(total_low_cred_labels, total_ensemble_low_cred_preds, labels=[0,1], average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 69  40]\n",
      " [  0 361]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(total_low_cred_labels, total_ensemble_low_cred_preds)\n",
    "tn, fp, fn, tp = confusion_matrix(total_low_cred_labels, total_ensemble_low_cred_preds).ravel()\n",
    "plot_confusion_matrix(confusion, classes=[\"Low Credibility\", \"High Credibility\"], filename='ensemble-performance', title=\"Ensemble Approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification for Credible Article Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8872340425531915\n",
      "Micro averaged f1-scores: 0.8872340425531915\n",
      "Micro averaged precision scores: 0.8872340425531915\n",
      "Micro averaged recall scores: 0.8872340425531915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_identified = []\n",
    "total_correct_diff = []\n",
    "total_incorrect_diff = []\n",
    "total_bin_low_cred_preds = []\n",
    "total_low_cred_labels = []\n",
    "total_y_scores = []\n",
    "total_y_test = []\n",
    "\n",
    "total_bin_preds = []\n",
    "total_bin_labels = []\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    models = defaultdict(str)\n",
    "    seed = random.randint(1,10000)\n",
    "    #Train a classifier for all 7 criteria\n",
    "    bin_clf = svm_build_train(article_text, labelled_articles['Credible'], seed)\n",
    "\n",
    "    #Replicate the X and y test sets to get the actual credibility score\n",
    "    __train, __test, __train, credibility_scores = train_test_split(article_text, list(labelled_articles[\"Score\"]), random_state=seed, test_size=0.10)\n",
    "    __train, __test, __train, low_credibility_labels = train_test_split(article_text, list(labelled_articles[\"Credible\"]), random_state=seed, test_size=0.10)\n",
    "\n",
    "    #I train a SVM using\n",
    "    predictions = list(bin_clf['model'].predict(bin_clf['X_test']))\n",
    "    \n",
    "    total_bin_preds.extend(predictions)\n",
    "    total_bin_labels.extend(list(bin_clf['y_test']))\n",
    "    total_y_scores.extend((bin_clf['model'].decision_function(bin_clf['X_test'])))\n",
    "    \n",
    "print(\"Accuracy: {}\".format(accuracy_score(total_bin_labels, total_bin_preds)))\n",
    "print(\"Micro averaged f1-scores: {}\".format(f1_score(total_bin_labels, total_bin_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged precision scores: {}\".format(precision_score(total_bin_labels, total_bin_preds, labels=[0,1], average='micro')))\n",
    "print(\"Micro averaged recall scores: {}\".format(recall_score(total_bin_labels, total_bin_preds, labels=[0,1], average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8fe81495c762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_bin_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_bin_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Low Credibility\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"High Credibility\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary-performance.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Binary Approach\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(total_bin_preds, total_bin_labels)\n",
    "plot_confusion_matrix(confusion, classes=[\"Low Credibility\", \"High Credibility\"], filename='binary-performance.png', title=\"Binary Approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(total_bin_labels, total_y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(total_bin_labels , total_y_scores, \"binary-roc-curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
